import psycopg2
import pandas as pd
SQL = """ SELECT * FROM tskv """
connection = psycopg2.connect(database = "tourism",user = "univer", password = "univer", host = "127.0.0.1", port =5432 )

tskv = pd.read_sql_query(SQL, connection)
print(tskv.info())


tskv.drop_duplicates()

gost = tskv[tskv['rubrics'] == "Гостиница"]
gost

import spacy
from spacy import load
from spacy.lang.ru import Russian

nlp = Russian()
load_model = load("ru_core_news_sm")

lemma = []

for item in load_model.pipe(hotel['text'].values):
    lemma.append(n.lemma_ for n in item)

gost['text'] = lemma

import nltk
from nltk.corpus import stopwords

nltk.download('stopwords')
stop_words = set(stopwords.words('russian'))

stopwords_ru = stopwords.words("russian")
hotel['text'] = hotel['text'].apply(lambda x:[item for item in x if item not in stopwords_ru])
hotel['text'] = [' '.join(map(str, j)) for j in hotel['text']]


df = hotel
df = df.drop(columns='text')
df
df = df.drop_duplicates(subset='clean_text')
df
# 0: NEUTRAL
# 1: POSITIVE
# 2: NEGATIVE

from transformers import pipeline

sentiment_analyzer = pipeline("text-classification", model="blanchefort/rubert-base-cased-sentiment", device=0)

label = []
score = []
x = 0 
for i in test_df['clean_text']:
    result = sentiment_analyzer(df['clean_text'].tolist()[x])
    label.append(result[0]['label'])
    score.append(result[0]['score'])
    x += 1
    print(len(label)," -> ", len(score))
test_df['label'] = label
test_df['score'] = score
test_df

test_df['label'] = test_df['label'].replace("POSITIVE", 1)
test_df['label'] = test_df['label'].replace("NEUTRAL", 0)
test_df['label'] = test_df['label'].replace("NEGATIVE", 2)

print(test_df.info())

from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns


vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(test_df['clean_text'])
scaler = StandardScaler()

kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit(X)

X_scaler = scaler.fit_transform(X.toarray())

plt.figure(figsize=(8,6))
sns.scatterplot(x=X_scaler[:,0], y=X_scaler[:,1],hue=clusters, palette='viridis')
plt.show()

X_scaler


from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

X = X_scaler

y = test_df['label']
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

knn = KNeighborsClassifier()
knn.fit(X_train,y_train)

predict = knn.predict(X_test)
predict

accurancy = accuracy_score(predict,y_test)
accurancy
import joblib

joblib.dump(knn,'test_model.pkl')
\





триграммы и двуграммы


from sklearn.feature_extraction.text import CountVectorizer

# Пример текста
text = ["Привет, как дела? У меня всё отлично, спасибо!"]

# Создание биграмм
bigram_vectorizer = CountVectorizer(ngram_range=(2, 2))
X = bigram_vectorizer.fit_transform(text)
print("Биграммы:", bigram_vectorizer.get_feature_names_out())

# Создание триграмм
trigram_vectorizer = CountVectorizer(ngram_range=(3, 3))
X = trigram_vectorizer.fit_transform(text)
print("Триграммы:", trigram_vectorizer.get_feature_names_out())





from sklearn.neighbors import NearestNeighbors
KDTree
